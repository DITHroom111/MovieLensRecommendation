{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f, types as t, Window\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "def transform_genre_no_filter(\n",
    "        ALS_model, ratings_dev, exploded_movies, genre_indexer, prediction_col, group_by_columns=[],\n",
    "        aggregation_func=f.avg,\n",
    "):\n",
    "    exploded_ratings = (\n",
    "        ratings_dev\n",
    "        .join(f.broadcast(exploded_movies), on='movieId')\n",
    "    )\n",
    "    exploded_ratings = genre_indexer.transform(exploded_ratings).drop('genre')\n",
    "    return (\n",
    "        ALS_model.transform(exploded_ratings)\n",
    "        .groupBy('userId', 'movieId', 'timestamp', *group_by_columns)\n",
    "        .agg(aggregation_func(prediction_col).alias(prediction_col))\n",
    "    )\n",
    "\n",
    "\n",
    "def transform_actor_no_filter(\n",
    "        ALS_model, ratings_dev, exploded_movies, prediction_col, group_by_columns=[],\n",
    "        aggregation_func=f.avg,\n",
    "):\n",
    "    exploded_ratings = (\n",
    "        ratings_dev\n",
    "        .join(f.broadcast(exploded_movies), on='movieId', how='left')\n",
    "        .withColumn('actor', f.when(f.isnull('actor'), -1).otherwise(f.col('actor')))\n",
    "    )\n",
    "    return (\n",
    "        ALS_model.transform(exploded_ratings)\n",
    "        .groupBy('userId', 'movieId', 'timestamp', *group_by_columns)\n",
    "        .agg(aggregation_func(prediction_col).alias(prediction_col))\n",
    "    )\n",
    "\n",
    "\n",
    "@f.udf(t.ArrayType(t.StringType()))\n",
    "def split_genres(genres):\n",
    "    \"\"\"Given as a string of genres concatenated with '|', splits it into array\"\"\"\n",
    "    return genres.split('|')\n",
    "\n",
    "\n",
    "@f.udf(t.ArrayType(t.IntegerType()))\n",
    "def split_actors(actors):\n",
    "    \"\"\"Given as a string of concatenated actor Ids in format 'nm<some_int>', splits it into array\"\"\"\n",
    "    return list(map(int, actors.split('nm')[1:])) if actors else []\n",
    "\n",
    "\n",
    "def load(paths, has_rating=True):\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "    result = (\n",
    "        spark.read.csv(paths, header=True)\n",
    "        .withColumn('userId', f.col('userId').cast('int'))\n",
    "        .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "        .withColumn('timestamp', f.col('timestamp').cast('int'))\n",
    "        .filter(f.col('userId').isNotNull())\n",
    "    )\n",
    "    if has_rating:\n",
    "        result = result.withColumn('rating', f.col('rating').cast('float'))\n",
    "    return result.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ALS = ALSModel.load('/user/mob2019014/user_movie_ALS_model.bin')\n",
    "user_genre_ALS = ALSModel.load('/user/mob2019014/user_genre_ALS_model.bin')\n",
    "user_actor_ALS = ALSModel.load('/user/mob2019014/user_actor_ALS_model.bin')\n",
    "\n",
    "ratings_test = load('/data/MobodMovieLens/test/ratings.csv', has_rating=False)\n",
    "\n",
    "movies = spark.read.csv('/data/MobodMovieLens/train/movies.csv', header=True).cache()\n",
    "exploded_movies = (\n",
    "    movies\n",
    "    .drop('title')\n",
    "    .withColumn('genres', split_genres(movies.genres))\n",
    "    .withColumn('genre', f.explode('genres')).drop('genres')\n",
    ")\n",
    "genre_indexer_creator = StringIndexer(inputCol='genre', outputCol='genreId')\n",
    "genre_indexer = genre_indexer_creator.fit(exploded_movies)\n",
    "\n",
    "exploded_by_actors_movies = (\n",
    "    spark.read.csv('/user/mob2019014/movies_imdb.csv', header=True)\n",
    "    .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "    .select('movieId', 'nconst')\n",
    "    .withColumn('actors', split_actors('nconst'))\n",
    "    .withColumn('actor', f.explode('actors'))\n",
    "    .drop('actors', 'nconst')\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_ALS = user_movie_ALS.transform(ratings_test)\n",
    "ratings_with_ALS = transform_genre_no_filter(\n",
    "    user_genre_ALS, ratings_with_ALS, exploded_movies, genre_indexer, 'user_genre_ALS',\n",
    "    group_by_columns=['user_movie_ALS'],\n",
    ")\n",
    "ratings_with_ALS = transform_actor_no_filter(\n",
    "    user_actor_ALS, ratings_with_ALS, exploded_by_actors_movies, 'user_actor_ALS',\n",
    "    group_by_columns=['user_movie_ALS', 'user_genre_ALS'],\n",
    ")\n",
    "ratings_with_ALS.repartition(1).write.csv(\n",
    "    'ratings_test_with_all_ALS_predictions.csv', header=True, mode='overwrite',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = (\n",
    "    \"hdfs dfs -cat \"\n",
    "    \"$(hdfs dfs -ls ratings_test_with_all_ALS_predictions.csv | awk '{if (NR == 3) print $8;}')\"\n",
    "    \" > ratings_test_with_all_ALS_predictions.csv\"\n",
    ")\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test = pd.read_csv('ratings_test_with_all_ALS_predictions.csv')\n",
    "# should load it from here https://yadi.sk/d/CFidwe3_JDaSbw\n",
    "movies_imdb = pd.read_csv('movies_imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onaga/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "movies_imdb['averageRating'] = movies_imdb['averageRating'] / 2\n",
    "genres = [\n",
    "    [el for el in x.split(',')] + ['None'] * (3 - len(x.split(',')))\n",
    "    for x in movies_imdb['genres_imdb']\n",
    "]\n",
    "movies_imdb['genres_imdb_0'] = [el[0] for el in genres]\n",
    "movies_imdb['genres_imdb_1'] = [el[1] for el in genres]\n",
    "movies_imdb['genres_imdb_2'] = [el[2] for el in genres]\n",
    "movies_imdb['runtimeMinutes'][movies_imdb['runtimeMinutes'] == '\\\\N'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test = pd.merge(als_final_test, movies_imdb, how='left', left_on=['movieId'], right_on=['movieId'])\n",
    "als_final_test['genres_imdb_0'].fillna('None', inplace=True)\n",
    "als_final_test['genres_imdb_1'].fillna('None', inplace=True)\n",
    "als_final_test['genres_imdb_2'].fillna('None', inplace=True)\n",
    "als_final_test['titleType'].fillna('None', inplace=True)\n",
    "als_final_test['curr_date'] = list(map(lambda x: datetime.fromtimestamp(x).isoformat(), als_final_test['timestamp']))\n",
    "als_final_test['curr_year'] = list(map(lambda x: float(x[:4]), als_final_test['curr_date']))\n",
    "als_final_test['curr_month'] = list(map(lambda x: x[5:7], als_final_test['curr_date']))\n",
    "als_final_test['movie_age'] = als_final_test['curr_year'] - als_final_test['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'user_movie_ALS', \n",
    "    'user_genre_ALS', \n",
    "    'user_actor_ALS', \n",
    "    'averageRating', \n",
    "    'isAdult', \n",
    "    'runtimeMinutes', \n",
    "    'numVotes', \n",
    "    'movie_age',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it here https://yadi.sk/d/VCi4KUoI7sa2sQ\n",
    "with open('saved_catboost_model_2.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test['prediction'] = model.predict(als_final_test[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test.to_csv(\n",
    "    'prediction_2.csv',\n",
    "    index=False,\n",
    "    columns=['movieId', 'userId', 'timestamp', 'prediction']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
