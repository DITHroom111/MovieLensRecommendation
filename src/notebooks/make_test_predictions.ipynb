{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and fucntions to calc ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f, types as t, Window\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "def transform_genre_no_filter(\n",
    "        ALS_model, ratings_dev, exploded_movies, genre_indexer, prediction_col, group_by_columns=[],\n",
    "        aggregation_func=f.avg,\n",
    "):\n",
    "    exploded_ratings = (\n",
    "        ratings_dev\n",
    "        .join(f.broadcast(exploded_movies), on='movieId')\n",
    "    )\n",
    "    exploded_ratings = genre_indexer.transform(exploded_ratings).drop('genre')\n",
    "    return (\n",
    "        ALS_model.transform(exploded_ratings)\n",
    "        .groupBy('userId', 'movieId', 'timestamp', *group_by_columns)\n",
    "        .agg(aggregation_func(prediction_col).alias(prediction_col))\n",
    "    )\n",
    "\n",
    "\n",
    "def transform_actor_no_filter(\n",
    "        ALS_model, ratings_dev, exploded_movies, prediction_col, group_by_columns=[],\n",
    "        aggregation_func=f.avg,\n",
    "):\n",
    "    exploded_ratings = (\n",
    "        ratings_dev\n",
    "        .join(f.broadcast(exploded_movies), on='movieId', how='left')\n",
    "        .withColumn('actor', f.when(f.isnull('actor'), -1).otherwise(f.col('actor')))\n",
    "    )\n",
    "    return (\n",
    "        ALS_model.transform(exploded_ratings)\n",
    "        .groupBy('userId', 'movieId', 'timestamp', *group_by_columns)\n",
    "        .agg(aggregation_func(prediction_col).alias(prediction_col))\n",
    "    )\n",
    "\n",
    "\n",
    "@f.udf(t.ArrayType(t.StringType()))\n",
    "def split_genres(genres):\n",
    "    \"\"\"Given as a string of genres concatenated with '|', splits it into array\"\"\"\n",
    "    return genres.split('|')\n",
    "\n",
    "\n",
    "@f.udf(t.ArrayType(t.IntegerType()))\n",
    "def split_actors(actors):\n",
    "    \"\"\"Given as a string of concatenated actor Ids in format 'nm<some_int>', splits it into array\"\"\"\n",
    "    return list(map(int, actors.split('nm')[1:])) if actors else []\n",
    "\n",
    "\n",
    "def load(paths, has_rating=True):\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "    result = (\n",
    "        spark.read.csv(paths, header=True)\n",
    "        .withColumn('userId', f.col('userId').cast('int'))\n",
    "        .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "        .withColumn('timestamp', f.col('timestamp').cast('int'))\n",
    "        .filter(f.col('userId').isNotNull())\n",
    "    )\n",
    "    if has_rating:\n",
    "        result = result.withColumn('rating', f.col('rating').cast('float'))\n",
    "    return result.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ALS = ALSModel.load('/user/mob2019014/user_movie_ALS_model.bin')\n",
    "user_genre_ALS = ALSModel.load('/user/mob2019014/user_genre_ALS_model.bin')\n",
    "user_actor_ALS = ALSModel.load('/user/mob2019014/user_actor_ALS_model.bin')\n",
    "\n",
    "ratings_test = load('/data/MobodMovieLens/test/ratings.csv', has_rating=False)\n",
    "\n",
    "movies = spark.read.csv('/data/MobodMovieLens/train/movies.csv', header=True).cache()\n",
    "exploded_movies = (\n",
    "    movies\n",
    "    .drop('title')\n",
    "    .withColumn('genres', split_genres(movies.genres))\n",
    "    .withColumn('genre', f.explode('genres')).drop('genres')\n",
    ")\n",
    "genre_indexer_creator = StringIndexer(inputCol='genre', outputCol='genreId')\n",
    "genre_indexer = genre_indexer_creator.fit(exploded_movies)\n",
    "\n",
    "exploded_by_actors_movies = (\n",
    "    spark.read.csv('/user/mob2019014/movies_imdb.csv', header=True)\n",
    "    .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "    .select('movieId', 'nconst')\n",
    "    .withColumn('actors', split_actors('nconst'))\n",
    "    .withColumn('actor', f.explode('actors'))\n",
    "    .drop('actors', 'nconst')\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_ALS = user_movie_ALS.transform(ratings_test)\n",
    "ratings_with_ALS = transform_genre_no_filter(\n",
    "    user_genre_ALS, ratings_with_ALS, exploded_movies, genre_indexer, 'user_genre_ALS',\n",
    "    group_by_columns=['user_movie_ALS'],\n",
    ")\n",
    "ratings_with_ALS = transform_actor_no_filter(\n",
    "    user_actor_ALS, ratings_with_ALS, exploded_by_actors_movies, 'user_actor_ALS',\n",
    "    group_by_columns=['user_movie_ALS', 'user_genre_ALS'],\n",
    ")\n",
    "ratings_with_ALS.repartition(1).write.csv(\n",
    "    'ratings_test_with_all_ALS_predictions.csv', header=True, mode='overwrite',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load them on disk from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = (\n",
    "    \"hdfs dfs -cat \"\n",
    "    \"$(hdfs dfs -ls ratings_test_with_all_ALS_predictions.csv | awk '{if (NR == 3) print $8;}')\"\n",
    "    \" > ratings_test_with_all_ALS_predictions.csv\"\n",
    ")\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to load data from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from stackoverflow\n",
    "# https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "  \n",
    "import requests\n",
    "\n",
    "\n",
    "def download_file_from_google_drive(file_id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={'id': file_id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {'id': file_id, 'confirm': token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test = pd.read_csv('ratings_test_with_all_ALS_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download IMDb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_from_google_drive('1j9JLdhT8ud5ps44CK6TJiT9bugJ4NPs_', 'movies_imdb.csv')\n",
    "movies_imdb = pd.read_csv('movies_imdb.csv')\n",
    "movies_imdb['averageRating'] = movies_imdb['averageRating'] / 2\n",
    "genres = [\n",
    "    [el for el in x.split(',')] + ['None'] * (3 - len(x.split(',')))\n",
    "    for x in movies_imdb['genres_imdb']\n",
    "]\n",
    "movies_imdb['genres_imdb_0'] = [el[0] for el in genres]\n",
    "movies_imdb['genres_imdb_1'] = [el[1] for el in genres]\n",
    "movies_imdb['genres_imdb_2'] = [el[2] for el in genres]\n",
    "movies_imdb['runtimeMinutes'][movies_imdb['runtimeMinutes'] == '\\\\N'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download linear models and make their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it may take around 30 mins :)\n",
    "# download_file_from_google_drive('1L8Ed-yVotKTgTTUki_58mfUIQXVgUAmy', 'inference.zip')\n",
    "# ! mkdir linear_model_inference && mv inference.zip linear_model_inference\n",
    "# ! cd linear_model_inference && unzip inference.zip\n",
    "# ! cd linear_model_inference && ./inference.sh ../ratings_test_with_all_ALS_predictions.csv\n",
    "# ! mv linear_model_inference/predictions.csv linear_predictions.csv\n",
    "\n",
    "# an alternative - simply download linear model scores from google drive:\n",
    "download_file_from_google_drive('1oKeLczBEaFYi_gJQRQ1GzyXSAUwa8Pql', 'linear_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge linear predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_features_final_test = pd.read_csv('linear_predictions.csv', header=None)\n",
    "lin_features_final_test.rename(\n",
    "    columns={0: 'fold', 1: 'userId', 2: 'movieId', 3: 'timestamp', 4: 'lin_pred'},\n",
    "    inplace=True,\n",
    ")\n",
    "als_final_test = pd.merge(\n",
    "    als_final_test, lin_features_final_test, how='left', \n",
    "    left_on=['userId', 'movieId', 'timestamp'], \n",
    "    right_on=['userId', 'movieId', 'timestamp'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge movies_imdb to test data and add time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test = pd.merge(als_final_test, movies_imdb, how='left', left_on=['movieId'], right_on=['movieId'])\n",
    "als_final_test['genres_imdb_0'].fillna('None', inplace=True)\n",
    "als_final_test['genres_imdb_1'].fillna('None', inplace=True)\n",
    "als_final_test['genres_imdb_2'].fillna('None', inplace=True)\n",
    "als_final_test['titleType'].fillna('None', inplace=True)\n",
    "als_final_test['curr_date'] = list(map(lambda x: datetime.fromtimestamp(x).isoformat(), als_final_test['timestamp']))\n",
    "als_final_test['curr_year'] = list(map(lambda x: float(x[:4]), als_final_test['curr_date']))\n",
    "als_final_test['curr_month'] = list(map(lambda x: x[5:7], als_final_test['curr_date']))\n",
    "als_final_test['movie_age'] = als_final_test['curr_year'] - als_final_test['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'user_movie_ALS', \n",
    "    'user_genre_ALS', \n",
    "    'user_actor_ALS', \n",
    "    'averageRating', \n",
    "    'isAdult', \n",
    "    'runtimeMinutes', \n",
    "    'numVotes', \n",
    "    'movie_age',\n",
    "    'lin_pred'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_from_google_drive('1eByw002RVPc0Fi7791PGBp7gHyA14TiW', 'catboost_model_v4.pkl')\n",
    "with open('catboost_model_v4.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test['prediction'] = model.predict(als_final_test[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test.to_csv(\n",
    "    'prediction.csv',\n",
    "    index=False,\n",
    "    columns=['movieId', 'userId', 'timestamp', 'prediction']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
