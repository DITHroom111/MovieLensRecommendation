{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make predictions on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, some imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f, types as t, Window\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "def transform_genre_no_filter(\n",
    "        ALS_model, ratings_dev, exploded_movies, genre_indexer, prediction_col, group_by_columns=[],\n",
    "        aggregation_func=f.avg,\n",
    "):\n",
    "    exploded_ratings = (\n",
    "        ratings_dev\n",
    "        .join(f.broadcast(exploded_movies), on='movieId')\n",
    "    )\n",
    "    exploded_ratings = genre_indexer.transform(exploded_ratings).drop('genre')\n",
    "    return (\n",
    "        ALS_model.transform(exploded_ratings)\n",
    "        .groupBy('userId', 'movieId', 'timestamp', *group_by_columns)\n",
    "        .agg(aggregation_func(prediction_col).alias(prediction_col))\n",
    "    )\n",
    "\n",
    "\n",
    "def transform_actor_no_filter(\n",
    "        ALS_model, ratings_dev, exploded_movies, prediction_col, group_by_columns=[],\n",
    "        aggregation_func=f.avg,\n",
    "):\n",
    "    exploded_ratings = (\n",
    "        ratings_dev\n",
    "        .join(f.broadcast(exploded_movies), on='movieId', how='left')\n",
    "        .withColumn('actor', f.when(f.isnull('actor'), -1).otherwise(f.col('actor')))\n",
    "    )\n",
    "    return (\n",
    "        ALS_model.transform(exploded_ratings)\n",
    "        .groupBy('userId', 'movieId', 'timestamp', *group_by_columns)\n",
    "        .agg(aggregation_func(prediction_col).alias(prediction_col))\n",
    "    )\n",
    "\n",
    "\n",
    "@f.udf(t.ArrayType(t.StringType()))\n",
    "def split_genres(genres):\n",
    "    \"\"\"Given as a string of genres concatenated with '|', splits it into array\"\"\"\n",
    "    return genres.split('|')\n",
    "\n",
    "\n",
    "@f.udf(t.ArrayType(t.IntegerType()))\n",
    "def split_actors(actors):\n",
    "    \"\"\"Given as a string of concatenated actor Ids in format 'nm<some_int>', splits it into array\"\"\"\n",
    "    return list(map(int, actors.split('nm')[1:])) if actors else []\n",
    "\n",
    "\n",
    "def load(paths, has_rating=True):\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "    result = (\n",
    "        spark.read.csv(paths, header=True)\n",
    "        .withColumn('userId', f.col('userId').cast('int'))\n",
    "        .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "        .withColumn('timestamp', f.col('timestamp').cast('int'))\n",
    "        .filter(f.col('userId').isNotNull())\n",
    "    )\n",
    "    if has_rating:\n",
    "        result = result.withColumn('rating', f.col('rating').cast('float'))\n",
    "    return result.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models and prepare movies datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_movie_ALS = ALSModel.load('/user/mob2019014/user_movie_ALS_model.bin')\n",
    "user_genre_ALS = ALSModel.load('/user/mob2019014/user_genre_ALS_model.bin')\n",
    "user_actor_ALS = ALSModel.load('/user/mob2019014/user_actor_ALS_model.bin')\n",
    "\n",
    "ratings_test = load('/data/MobodMovieLens/test/ratings.csv', has_rating=False)\n",
    "\n",
    "movies = spark.read.csv('/data/MobodMovieLens/train/movies.csv', header=True).cache()\n",
    "exploded_movies = (\n",
    "    movies\n",
    "    .drop('title')\n",
    "    .withColumn('genres', split_genres(movies.genres))\n",
    "    .withColumn('genre', f.explode('genres')).drop('genres')\n",
    ")\n",
    "genre_indexer_creator = StringIndexer(inputCol='genre', outputCol='genreId')\n",
    "genre_indexer = genre_indexer_creator.fit(exploded_movies)\n",
    "\n",
    "exploded_by_actors_movies = (\n",
    "    spark.read.csv('/user/mob2019014/movies_imdb.csv', header=True)\n",
    "    .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "    .select('movieId', 'nconst')\n",
    "    .withColumn('actors', split_actors('nconst'))\n",
    "    .withColumn('actor', f.explode('actors'))\n",
    "    .drop('actors', 'nconst')\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make ALS predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_with_ALS = user_movie_ALS.transform(ratings_test)\n",
    "ratings_with_ALS = transform_genre_no_filter(\n",
    "    user_genre_ALS, ratings_with_ALS, exploded_movies, genre_indexer, 'user_genre_ALS',\n",
    "    group_by_columns=['user_movie_ALS'],\n",
    ")\n",
    "ratings_with_ALS = transform_actor_no_filter(\n",
    "    user_actor_ALS, ratings_with_ALS, exploded_by_actors_movies, 'user_actor_ALS',\n",
    "    group_by_columns=['user_movie_ALS', 'user_genre_ALS'],\n",
    ")\n",
    "ratings_with_ALS.repartition(1).write.csv(\n",
    "    'ratings_test_with_all_ALS_predictions.csv', header=True, mode='overwrite',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv with predictions on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = (\n",
    "    \"hdfs dfs -cat \"\n",
    "    \"$(hdfs dfs -ls ratings_test_with_all_ALS_predictions.csv | awk '{if (NR == 3) print $8;}')\"\n",
    "    \" > ratings_test_with_all_ALS_predictions.csv\"\n",
    ")\n",
    "subprocess.call(command, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
