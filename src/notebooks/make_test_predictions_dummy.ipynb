{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and fucntions to calc ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f, types as t, Window\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "def load(paths, has_rating=True):\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "    result = (\n",
    "        spark.read.csv(paths, header=True)\n",
    "        .withColumn('userId', f.col('userId').cast('int'))\n",
    "        .withColumn('movieId', f.col('movieId').cast('int'))\n",
    "        .withColumn('timestamp', f.col('timestamp').cast('int'))\n",
    "        .filter(f.col('userId').isNotNull())\n",
    "    )\n",
    "    if has_rating:\n",
    "        result = result.withColumn('rating', f.col('rating').cast('float'))\n",
    "    return result.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ALS = ALSModel.load('/user/mob2019014/user_movie_ALS_model.bin')\n",
    "\n",
    "ratings_test = load('/data/MobodMovieLens/test/ratings.csv', has_rating=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_ALS = user_movie_ALS.transform(ratings_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load them on disk from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = (\n",
    "    \"hdfs dfs -cat \"\n",
    "    \"$(hdfs dfs -ls ratings_test_with_all_ALS_predictions.csv | awk '{if (NR == 3) print $8;}')\"\n",
    "    \" > ratings_test_with_all_ALS_predictions.csv\"\n",
    ")\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to load data from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "als_final_test = pd.read_csv('ratings_test_with_all_ALS_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_final_test['prediction'] = als_final_test['user_movie_ALS']\n",
    "als_final_test.fillna(3.5).to_csv(\n",
    "    'prediction.csv',\n",
    "    index=False,\n",
    "    columns=['movieId', 'userId', 'timestamp', 'prediction']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
